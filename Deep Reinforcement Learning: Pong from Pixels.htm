<!DOCTYPE html>
<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Deep Reinforcement Learning: Pong from Pixels</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="Musings of a Computer Scientist.">
    <link rel="canonical" href="http://karpathy.github.io/2016/05/31/rl/">
    <link href="http://karpathy.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Andrej Karpathy blog posts">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/main.css">

    <!-- Google Analytics -->
    <script async="" src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/analytics.js"></script><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-3698471-23', 'auto');
      ga('send', 'pageview');
    </script>

<script type="text/javascript" async="" src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/embed.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Main; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.0') format('opentype'); font-weight: bold}
@font-face {font-family: MathJax_Main; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.0') format('opentype'); font-style: italic}
@font-face {font-family: MathJax_Math; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.0') format('opentype'); font-style: italic}
@font-face {font-family: MathJax_Caligraphic; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.0') format('opentype')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><script src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/alfie.js" async="" charset="UTF-8"></script></head>


    <body><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px none; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

    <header class="site-header">

  <div class="wrap">

    <div style="float:left; margin-top:10px; margin-right:10px;">
    <a href="http://karpathy.github.io/feed.xml">
      <img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/rssicon.svg" width="40">
    </a>
    </div>

    <a class="site-title" href="http://karpathy.github.io/">Andrej Karpathy blog</a>
    
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path>
        </svg>
      </a>
      <div class="trigger">
        
          <a class="page-link" href="http://karpathy.github.io/about/">About</a>
        
          
        
          
        
          <a class="page-link" href="http://karpathy.github.io/neuralnets/">Hacker's guide to Neural Networks</a>
        
          
        
      </div>
    </nav>
  </div>

</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>Deep Reinforcement Learning: Pong from Pixels</h1>
    <p class="meta">May 31, 2016</p>
  </header>

  <article class="post-content">
  <!-- 
<svg width="800" height="200">
	<rect width="800" height="200" style="fill:rgb(98,51,20)" />
	<rect width="20" height="50" x="20" y="100" style="fill:rgb(189,106,53)" />
	<rect width="20" height="50" x="760" y="30" style="fill:rgb(77,175,75)" />
	<rect width="10" height="10" x="400" y="60" style="fill:rgb(225,229,224)" />
</svg>
 -->

<p>This is a long overdue blog post on Reinforcement Learning (RL). RL 
is hot! You may have noticed that computers can now automatically <a href="http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html">learn to play ATARI games</a> (from raw game pixels!), they are beating world champions at <a href="http://googleresearch.blogspot.com/2016/01/alphago-mastering-ancient-game-of-go.html">Go</a>, simulated quadrupeds are learning to <a href="https://www.cs.ubc.ca/%7Evan/papers/2016-TOG-deepRL/index.html">run and leap</a>, and robots are learning how to perform <a href="http://www.bloomberg.com/features/2015-preschool-for-robots/">complex manipulation tasks</a>
 that defy explicit programming. It turns out that all of these advances
 fall under the umbrella of RL research. I also became interested in RL 
myself over the last ~year: I worked <a href="https://webdocs.cs.ualberta.ca/%7Esutton/book/the-book.html">through Richard Sutton’s book</a>, read through <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">David Silver’s course</a>, watched <a href="https://www.youtube.com/watch?v=oPGVsoBonLM">John Schulmann’s lectures</a>, wrote an <a href="http://cs.stanford.edu/people/karpathy/reinforcejs/">RL library in Javascript</a>,
 over the  summer interned at DeepMind working in the DeepRL group, and 
most recently pitched in a little with the design/development of <a href="https://gym.openai.com/">OpenAI Gym</a>,
 a new RL benchmarking toolkit. So I’ve certainly been on this funwagon 
for at least a year but until now I haven’t gotten around to writing up a
 short post on why RL is a big deal, what it’s about, how it all 
developed and where it might be going.</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/preview.jpeg">
<div class="thecap">Examples of RL in the wild. <b>From left to right</b>:
 Deep Q Learning network playing ATARI, AlphaGo, Berkeley robot stacking
 Legos, physically-simulated quadruped leaping over terrain.</div>
</div>

<p>It’s interesting to reflect on the nature of recent progress in RL. I
 broadly like to think about four separate factors that hold back AI:</p>

<ol>
  <li>Compute (the obvious one: Moore’s Law, GPUs, ASICs),</li>
  <li>Data (in a nice form, not just out there somewhere on the internet - e.g. ImageNet),</li>
  <li>Algorithms (research and ideas, e.g. backprop, CNN, LSTM), and</li>
  <li>Infrastructure (software under you - Linux, TCP/IP, Git, ROS, PR2, AWS, AMT, TensorFlow, etc.).</li>
</ol>

<p>Similar to what happened in Computer Vision, the progress in RL is 
not driven as much as you might reasonably assume by new amazing ideas. 
In Computer Vision, the 2012 AlexNet was mostly a scaled up (deeper and 
wider) version of 1990’s ConvNets. Similarly, the ATARI Deep Q Learning 
paper from 2013 is an implementation of a standard algorithm (Q Learning
 with function approximation, which you can find in the standard RL book
 of Sutton 1998), where the function approximator happened to be a 
ConvNet. AlphaGo uses policy gradients with Monte Carlo Tree Search 
(MCTS) - these are also standard components. Of course, it takes a lot 
of skill and patience to get it to work, and multiple clever tweaks on 
top of old algorithms have been developed, but to a first-order 
approximation the main driver of recent progress is not the algorithms 
but (similar to Computer Vision) compute/data/infrastructure.</p>

<p>Now back to RL. Whenever there is a disconnect between how magical 
something seems and how simple it is under the hood I get all antsy and 
really want to write a blog post. In this case I’ve seen many people who
 can’t believe that we can automatically learn to play most ATARI games 
at human level, with one algorithm, from pixels, and from scratch - and 
it is amazing, and I’ve been there myself! But at the core the approach 
we use is also really quite profoundly dumb (though I understand it’s 
easy to make such claims in retrospect). Anyway, I’d like to walk you 
through Policy Gradients (PG), our favorite default choice for attacking
 RL problems at the moment. If you’re from outside of RL you might be 
curious why I’m not presenting DQN instead, which is an alternative and 
better-known RL algorithm, widely popularized by the <a href="http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html">ATARI game playing paper</a>.
 It turns out that Q-Learning is not a great algorithm (you could say 
that DQN is so 2013 (okay I’m 50% joking)). In fact most people prefer 
to use Policy Gradients, including the authors of the original DQN paper
 who have <a href="http://arxiv.org/abs/1602.01783">shown</a> Policy 
Gradients to work better than Q Learning when tuned well. PG is 
preferred because it is end-to-end: there’s an explicit policy and a 
principled approach that directly optimizes the expected reward. Anyway,
 as a running example we’ll learn to play an ATARI game (Pong!) with PG,
 from scratch, from pixels, with a deep neural network, and the whole 
thing is 130 lines of Python only using numpy as a dependency (<a href="https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5">Gist link</a>). Lets get to it.</p>

<h3 id="pong-from-pixels">Pong from pixels</h3>

<div class="imgcap">
<div style="display:inline-block">
	<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/pong.gif">
</div>
<div style="display:inline-block; margin-left: 20px;">
	<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/mdp.png" height="206">
</div>
<div class="thecap"><b>Left:</b> The game of Pong. <b>Right:</b> Pong is a special case of a <a href="https://en.wikipedia.org/wiki/Markov_decision_process">Markov Decision Process (MDP)</a>:
 A graph where each node is a particular game state and each edge is a 
possible (in general probabilistic) transition. Each edge also gives a 
reward, and the goal is to compute the optimal way of acting in any 
state to maximize rewards.</div>
</div>

<p>The game of Pong is an excellent example of a simple RL task. In the 
ATARI 2600 version we’ll use you play as one of the paddles (the other 
is controlled by a decent AI) and you have to bounce the ball past the 
other player (I don’t really have to explain Pong, right?). On the low 
level the game works as follows: we receive an image frame (a <code class="highlighter-rouge">210x160x3</code>
 byte array (integers from 0 to 255 giving pixel values)) and we get to 
decide if we want to move the paddle UP or DOWN (i.e. a binary choice). 
After every single choice the game simulator executes the action and 
gives us a reward: Either a +1 reward if the ball went past the 
opponent, a -1 reward if we missed the ball, or 0 otherwise. And of 
course, our goal is to move the paddle so that we get lots of reward.</p>

<p>As we go through the solution keep in mind that we’ll try to make 
very few assumptions about Pong because we secretly don’t really care 
about Pong; We care about complex, high-dimensional problems like robot 
manipulation, assembly and navigation. Pong is just a fun toy test case,
 something we play with while we figure out how to write very general AI
 systems that can one day do arbitrary useful tasks.</p>

<p><strong>Policy network</strong>. First, we’re going to define a <em>policy network</em>
 that implements our player (or “agent”). This network will take the 
state of the game and decide what we should do (move UP or DOWN). As our
 favorite simple block of compute we’ll use a 2-layer neural network 
that takes the raw image pixels (100,800 numbers total (210*160*3)), and
 produces a single number indicating the probability of going UP. Note 
that it is standard to use a <em>stochastic</em> policy, meaning that we only produce a <em>probability</em>
 of moving UP. Every iteration we will sample from this distribution 
(i.e. toss a biased coin) to get the actual move. The reason for this 
will become more clear once we talk about training.</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/policy.png" height="200">
<div class="thecap">Our policy network is a 2-layer fully-connected net.</div>
</div>

<p>and to make things concrete here is how you might implement this policy network in Python/numpy. Suppose we’re given a vector <code class="highlighter-rouge">x</code> that holds the (preprocessed) pixel information. We would compute:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="c"># compute hidden layer neuron activations</span>
<span class="n">h</span><span class="p">[</span><span class="n">h</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c"># ReLU nonlinearity: threshold at zero</span>
<span class="n">logp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="c"># compute log probability of going up</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">logp</span><span class="p">))</span> <span class="c"># sigmoid function (gives probability of going up)</span>
</code></pre>
</div>

<p>where in this snippet <code class="highlighter-rouge">W1</code> and <code class="highlighter-rouge">W2</code> are two matrices that we initialize randomly. We’re not using biases because meh. Notice that we use the <em>sigmoid</em>
 non-linearity at the end, which squashes the output probability to the 
range [0,1]. Intuitively, the neurons in the hidden layer (which have 
their weights arranged along the rows of <code class="highlighter-rouge">W1</code>) can detect various game scenarios (e.g. the ball is in the top, and our paddle is in the middle), and the weights in <code class="highlighter-rouge">W2</code> can then decide if in each case we should be going UP or DOWN. Now, the initial random <code class="highlighter-rouge">W1</code> and <code class="highlighter-rouge">W2</code> will of course cause the player to spasm on spot. So the only problem now is to find <code class="highlighter-rouge">W1</code> and <code class="highlighter-rouge">W2</code> that lead to expert play of Pong!</p>

<p><em>Fine print: preprocessing.</em> Ideally you’d want to feed at 
least 2 frames to the policy network so that it can detect motion. To 
make things a bit simpler (I did these experiments on my Macbook) I’ll 
do a tiny bit of preprocessing, e.g. we’ll actually feed <em>difference frames</em> to the network (i.e. subtraction of current and last frame).</p>

<p><strong>It sounds kind of impossible</strong>. At this point I’d like
 you to appreciate just how difficult the RL problem is. We get 100,800 
numbers (210*160*3) and forward our policy network (which easily 
involves on order of a million parameters in <code class="highlighter-rouge">W1</code> and <code class="highlighter-rouge">W2</code>).
 Suppose that we decide to go UP. The game might respond that we get 0 
reward this time step and gives us another 100,800 numbers for the next 
frame. We could repeat this process for hundred timesteps before we get 
any non-zero reward! E.g. suppose we finally get a +1. That’s great, but
 how can we tell what made that happen? Was it something we did just 
now? Or maybe 76 frames ago? Or maybe it had something to do with frame 
10 and then frame 90? And how do we figure out which of the million 
knobs to change and how, in order to do better in the future? We call 
this the <em>credit assignment problem</em>. In the specific case of Pong we know that we get a +1 if the ball makes it past the opponent. The <em>true</em>
 cause is that we happened to bounce the ball on a good trajectory, but 
in fact we did so many frames ago - e.g. maybe about 20 in case of Pong,
 and every single action we did afterwards had zero effect on whether or
 not we end up getting the reward. In other words we’re faced with a 
very difficult problem and things are looking quite bleak.</p>

<p><strong>Supervised Learning</strong>. Before we dive into the Policy 
Gradients solution I’d like to remind you briefly about supervised 
learning because, as we’ll see, RL is very similar. Refer to the diagram
 below. In ordinary supervised learning we would feed an image to the 
network and get some probabilities, e.g. for two classes UP and DOWN. 
I’m showing log probabilities (-1.2, -0.36) for UP and DOWN instead of 
the raw probabilities (30% and 70% in this case) because we always 
optimize the log probability of the correct label (this makes math 
nicer, and is equivalent to optimizing the raw probability because log 
is monotonic). Now, in supervised learning we would have access to a 
label. For example, we might be told that the correct thing to do right 
now is to go UP (label 0). In an implementation we would enter gradient 
of 1.0 on the log probability of UP and run backprop to compute the 
gradient vector <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;U&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 12.166em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.327em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1009.23em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="msubsup" id="MathJax-Span-3"><span style="display: inline-block; position: relative; width: 1.649em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-4" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.833em;"><span class="texatom" id="MathJax-Span-5"><span class="mrow" id="MathJax-Span-6"><span class="mi" id="MathJax-Span-7" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.074em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-8" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-9"></span><span class="mi" id="MathJax-Span-10" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-11" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-12" style="font-family: MathJax_Math; font-style: italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.006em;"></span></span><span class="mo" id="MathJax-Span-13" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mi" id="MathJax-Span-14" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.278em;">U<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.084em;"></span></span><span class="mi" id="MathJax-Span-15" style="font-family: MathJax_Math; font-style: italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-16" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="mi" id="MathJax-Span-17" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.278em;">x</span><span class="mo" id="MathJax-Span-18" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>W</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mi>U</mi><mi>P</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-1">\nabla_{W} \log p(y=UP \mid x) </script>.
 This gradient would tell us how we should change every one of our 
million parameters to make the network slightly more likely to predict 
UP. For example, one of the million parameters in the network might have
 a gradient of -2.1, which means that if we were to increase that 
parameter by a small positive amount (e.g. <code class="highlighter-rouge">0.001</code>), the log probability of UP would decrease by <code class="highlighter-rouge">2.1 * 0.001</code>
 (decrease due to the negative sign). If we then did a parameter update 
then, yay, our network would now be slightly more likely to predict UP 
when it sees a very similar image in the future.</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/sl.png">
</div>

<p><strong>Policy Gradients</strong>. Okay, but what do we do if we do 
not have the correct label in the Reinforcement Learning setting? Here 
is the Policy Gradients solution (again refer to diagram below). Our 
policy network calculated probability of going UP as 30% (logprob -1.2) 
and DOWN as 70% (logprob -0.36). We will now sample an action from this 
distribution; E.g. suppose we sample DOWN, and we will execute it in the
 game. At this point notice one interesting fact: We could immediately 
fill in a gradient of 1.0 for DOWN as we did in supervised learning, and
 find the gradient vector that would encourage the network to be 
slightly more likely to do the DOWN action in the future. So we can 
immediately evaluate this gradient and that’s great, but the problem is 
that at least for now we do not yet know if going DOWN is good. But the 
critical point is that that’s okay, because we can simply wait a bit and
 see! For example in Pong we could wait until the end of the game, then 
take the reward we get (either +1 if we won or -1 if we lost), and enter
 that scalar as the gradient for the action we have taken (DOWN in this 
case). In the example below, going DOWN ended up to us losing the game 
(-1 reward). So if we fill in -1 for log probability of DOWN and do 
backprop we will find a gradient that <em>discourages</em> the network 
to take the DOWN action for that input in the future (and rightly so, 
since taking that action led to us losing the game).</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/rl.png">
</div>

<p>And that’s it: we have a stochastic policy that samples actions and 
then actions that happen to eventually lead to good outcomes get 
encouraged in the future, and actions taken that lead to bad outcomes 
get discouraged. Also, the reward does not even need to be +1 or -1 if 
we win the game eventually. It can be an arbitrary measure of some kind 
of eventual quality. For example if things turn out really well it could
 be 10.0, which we would then enter as the gradient instead of -1 to 
start off backprop. That’s the beauty of neural nets; Using them can 
feel like cheating: You’re allowed to have 1 million parameters embedded
 in 1 teraflop of compute and you can make it do arbitrary things with 
SGD. It shouldn’t work, but amusingly we live in a universe where it 
does.</p>

<p><strong>Training protocol.</strong> So here is how the training will work in detail. We will initialize the policy network with some <code class="highlighter-rouge">W1</code>, <code class="highlighter-rouge">W2</code>
 and play 100 games of Pong (we call these policy “rollouts”). Lets 
assume that each game is made up of 200 frames so in total we’ve made 
20,000 decisions for going UP or DOWN and for each one of these we know 
the parameter gradient, which tells us how we should change the 
parameters if we wanted to encourage that decision in that state in the 
future. All that remains now is to label every decision we’ve made as 
good or bad. For example suppose we won 12 games and lost 88. We’ll take
 all 200*12 = 2400 decisions we made in the winning games and do a 
positive update (filling in a +1.0 in the gradient for the sampled 
action, doing backprop, and parameter update encouraging the actions we 
picked in all those states). And we’ll take the other 200*88 = 17600 
decisions we made in the losing games and do a negative update 
(discouraging whatever we did). And… that’s it. The network will now 
become slightly more likely to repeat actions that worked, and slightly 
less likely to repeat actions that didn’t work. Now we play another 100 
games with our new, slightly improved policy and rinse and repeat.</p>

<blockquote>
  <p>Policy Gradients: Run a policy for a while. See what actions led to high rewards. Increase their probability.</p>
</blockquote>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/episodes.png">
<div class="thecap" style="text-align:justify;">Cartoon diagram of 4 
games. Each black circle is some game state (three example states are 
visualized on the bottom), and each arrow is a transition, annotated 
with the action that was sampled. In this case we won 2 games and lost 2
 games. With Policy Gradients we would take the two games we won and 
slightly encourage every single action we made in that episode. 
Conversely, we would also take the two games we lost and slightly 
discourage every single action we made in that episode.</div>
</div>

<p>If you think through this process you’ll start to find a few funny 
properties. For example what if we made a good action in frame 50 
(bouncing the ball back correctly), but then missed the ball in frame 
150? If every single action is now labeled as bad (because we lost), 
wouldn’t that discourage the correct bounce on frame 50? You’re right - 
it would. However, when you consider the process over thousands/millions
 of games, then doing the first bounce correctly makes you slightly more
 likely to win down the road, so on average you’ll see more positive 
than negative updates for the correct bounce and your policy will end up
 doing the right thing.</p>

<p><strong>Update: December 9, 2016 - alternative view</strong>. In my 
explanation above I use the terms such as “fill in the gradient and 
backprop”, which I realize is a special kind of thinking if you’re used 
to writing your own backprop code, or using Torch where the gradients 
are explicit and open for tinkering. However, if you’re used to Theano 
or TensorFlow you might be a little perplexed because the code is 
oranized around specifying a loss function and the backprop is fully 
automatic and hard to tinker with. In this case, the following 
alternative view might be more intuitive. In vanilla supervised learning
 the objective is to maximize <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-19" style="width: 8.897em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.827em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1006.73em, 2.697em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-20"><span class="munderover" id="MathJax-Span-21"><span style="display: inline-block; position: relative; width: 1.375em; height: 0px;"><span style="position: absolute; clip: rect(3.096em, 1001em, 4.385em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-22" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.705em; left: 1.056em;"><span class="mi" id="MathJax-Span-23" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-24" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-25"></span><span class="mi" id="MathJax-Span-26" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-27" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-28"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.5em, 4.34em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-29" style="font-family: MathJax_Math; font-style: italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.006em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.49em;"><span class="mi" id="MathJax-Span-30" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-31" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="msubsup" id="MathJax-Span-32" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 0.891em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.52em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-33" style="font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.572em;"><span class="mi" id="MathJax-Span-34" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-35" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.444em; border-left: 0px solid; width: 0px; height: 1.481em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo>∑</mo><mi>i</mi></munder><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> \sum_i \log p(y_i \mid x_i) </script> where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-36" style="width: 2.839em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.163em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.673em, 1002.16em, 2.609em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-37"><span class="msubsup" id="MathJax-Span-38"><span style="display: inline-block; position: relative; width: 0.891em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.52em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-39" style="font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.572em;"><span class="mi" id="MathJax-Span-40" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-41" style="font-family: MathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-42" style="padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.5em, 4.34em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-43" style="font-family: MathJax_Math; font-style: italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.006em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.49em;"><span class="mi" id="MathJax-Span-44" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.329em; border-left: 0px solid; width: 0px; height: 0.966em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-3">x_i, y_i </script>
 are training examples (such as images and their labels). Policy 
gradients is exactly the same as supervised learning with two minor 
differences: 1) We don’t have the correct labels <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-45" style="width: 1.06em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.817em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.82em, 2.561em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-46"><span class="msubsup" id="MathJax-Span-47"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.5em, 4.34em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-48" style="font-family: MathJax_Math; font-style: italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.006em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.49em;"><span class="mi" id="MathJax-Span-49" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.329em; border-left: 0px solid; width: 0px; height: 0.966em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>y</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-4">y_i</script> so as a “fake label” we substitute the action we happened to sample from the policy when it saw <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-50" style="width: 1.204em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.913em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.91em, 2.514em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-51"><span class="msubsup" id="MathJax-Span-52"><span style="display: inline-block; position: relative; width: 0.891em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.52em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-53" style="font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.572em;"><span class="mi" id="MathJax-Span-54" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.268em; border-left: 0px solid; width: 0px; height: 0.905em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-5">x_i</script>,
 and 2) We modulate the loss for each example multiplicatively based on 
the eventual outcome, since we want to increase the log probability for 
actions that worked and decrease it for those that didn’t. So in summary
 our loss now looks like <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-55" style="width: 10.531em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.077em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1007.98em, 2.697em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-56"><span class="munderover" id="MathJax-Span-57"><span style="display: inline-block; position: relative; width: 1.375em; height: 0px;"><span style="position: absolute; clip: rect(3.096em, 1001em, 4.385em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-58" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.705em; left: 1.056em;"><span class="mi" id="MathJax-Span-59" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-60" style="padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 1.069em; height: 0px;"><span style="position: absolute; clip: rect(3.13em, 1000.73em, 4.135em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-61" style="font-family: MathJax_Math; font-style: italic;">A</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.75em;"><span class="mi" id="MathJax-Span-62" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-63" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-64"></span><span class="mi" id="MathJax-Span-65" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-66" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-67"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.5em, 4.34em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-68" style="font-family: MathJax_Math; font-style: italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.006em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.49em;"><span class="mi" id="MathJax-Span-69" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-70" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="msubsup" id="MathJax-Span-71" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 0.891em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.52em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-72" style="font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.572em;"><span class="mi" id="MathJax-Span-73" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-74" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.444em; border-left: 0px solid; width: 0px; height: 1.481em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>A</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-6"> \sum_i A_i \log p(y_i \mid x_i) </script>, where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-75" style="width: 1.06em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.817em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.82em, 2.561em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-76"><span class="msubsup" id="MathJax-Span-77"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.5em, 4.34em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-78" style="font-family: MathJax_Math; font-style: italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.006em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.49em;"><span class="mi" id="MathJax-Span-79" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.329em; border-left: 0px solid; width: 0px; height: 0.966em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>y</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7">y_i</script> is the action we happened to sample and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-80" style="width: 1.397em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.058em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.351em, 1001.06em, 2.514em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-81"><span class="msubsup" id="MathJax-Span-82"><span style="display: inline-block; position: relative; width: 1.069em; height: 0px;"><span style="position: absolute; clip: rect(3.13em, 1000.73em, 4.135em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-83" style="font-family: MathJax_Math; font-style: italic;">A</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.75em;"><span class="mi" id="MathJax-Span-84" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.268em; border-left: 0px solid; width: 0px; height: 1.261em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>A</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-8">A_i</script> is a number that we call an <strong>advantage</strong>. In the case of Pong, for example, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-85" style="width: 1.397em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.058em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.351em, 1001.06em, 2.514em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-86"><span class="msubsup" id="MathJax-Span-87"><span style="display: inline-block; position: relative; width: 1.069em; height: 0px;"><span style="position: absolute; clip: rect(3.13em, 1000.73em, 4.135em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-88" style="font-family: MathJax_Math; font-style: italic;">A</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.75em;"><span class="mi" id="MathJax-Span-89" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.268em; border-left: 0px solid; width: 0px; height: 1.261em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>A</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9">A_i</script> could be 1.0 if we eventually won in the episode that contained <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-90" style="width: 1.204em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.913em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.91em, 2.514em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-91"><span class="msubsup" id="MathJax-Span-92"><span style="display: inline-block; position: relative; width: 0.891em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.52em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-93" style="font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.572em;"><span class="mi" id="MathJax-Span-94" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">i</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.268em; border-left: 0px solid; width: 0px; height: 0.905em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-10">x_i</script>
 and -1.0 if we lost. This will ensure that we maximize the log 
probability of actions that led to good outcome and minimize the log 
probability of those that didn’t. So reinforcement learning is exactly 
like supervised learning, but on a continuously changing dataset (the 
episodes), scaled by the advantage, and we only want to do one (or very 
few) updates based on each sampled dataset.</p>

<p><strong>More general advantage functions</strong>. I also promised a bit more discussion of the returns. So far we have judged the <em>goodness</em> of every individual action based on whether or not we win the game. In a more general RL setting we would receive some reward <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-95" style="width: 1.012em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.769em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.77em, 2.514em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-96"><span class="msubsup" id="MathJax-Span-97"><span style="display: inline-block; position: relative; width: 0.781em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.43em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-98" style="font-family: MathJax_Math; font-style: italic;">r</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.451em;"><span class="mi" id="MathJax-Span-99" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">t</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.268em; border-left: 0px solid; width: 0px; height: 0.905em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-11">r_t</script>
 at every time step. One common choice is to use a discounted reward, so
 the “eventual reward” in the diagram above would become <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x221E;&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msup&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msup&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-100" style="width: 10.099em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.74em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.262em, 1007.74em, 2.705em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-101"><span class="msubsup" id="MathJax-Span-102"><span style="display: inline-block; position: relative; width: 1.089em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.76em, 4.156em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-103" style="font-family: MathJax_Math; font-style: italic;">R</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.759em;"><span class="mi" id="MathJax-Span-104" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">t</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-105" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="munderover" id="MathJax-Span-106" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 2.403em; height: 0px;"><span style="position: absolute; clip: rect(3.096em, 1001em, 4.385em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-107" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.534em, 1000.78em, 4.142em, -1000em); top: -4.467em; left: 1.056em;"><span class="texatom" id="MathJax-Span-108"><span class="mrow" id="MathJax-Span-109"><span class="mi" id="MathJax-Span-110" style="font-size: 70.7%; font-family: MathJax_Main;">∞</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.355em, 1001.35em, 4.15em, -1000em); top: -3.705em; left: 1.056em;"><span class="texatom" id="MathJax-Span-111"><span class="mrow" id="MathJax-Span-112"><span class="mi" id="MathJax-Span-113" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">k</span><span class="mo" id="MathJax-Span-114" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-115" style="font-size: 70.7%; font-family: MathJax_Main;">0</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-116" style="padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px;"><span style="position: absolute; clip: rect(3.405em, 1000.54em, 4.351em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-117" style="font-family: MathJax_Math; font-style: italic;">γ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.025em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -4.353em; left: 0.601em;"><span class="mi" id="MathJax-Span-118" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">k</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-119"><span style="display: inline-block; position: relative; width: 1.7em; height: 0px;"><span style="position: absolute; clip: rect(3.404em, 1000.43em, 4.146em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-120" style="font-family: MathJax_Math; font-style: italic;">r</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.451em;"><span class="texatom" id="MathJax-Span-121"><span class="mrow" id="MathJax-Span-122"><span class="mi" id="MathJax-Span-123" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">t</span><span class="mo" id="MathJax-Span-124" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mi" id="MathJax-Span-125" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">k</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.454em; border-left: 0px solid; width: 0px; height: 1.626em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>R</mi><mi>t</mi></msub><mo>=</mo><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="normal">∞</mi></mrow></munderover><msup><mi>γ</mi><mi>k</mi></msup><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mi>k</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-12"> R_t = \sum_{k=0}^{\infty} \gamma^k r_{t+k} </script>, where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-126" style="width: 0.772em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.577em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.626em, 1000.58em, 2.572em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-127"><span class="mi" id="MathJax-Span-128" style="font-family: MathJax_Math; font-style: italic;">γ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.025em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.343em; border-left: 0px solid; width: 0px; height: 0.979em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>γ</mi></math></span></span><script type="math/tex" id="MathJax-Element-13">\gamma</script>
 is a number between 0 and 1 called a discount factor (e.g. 0.99). The 
expression states that the strength with which we encourage a sampled 
action is the weighted sum of all rewards afterwards, but later rewards 
are exponentially less important. In practice it can can also be 
important to normalize these. For example, suppose we compute <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-129" style="width: 1.445em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.106em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.384em, 1001.11em, 2.514em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-130"><span class="msubsup" id="MathJax-Span-131"><span style="display: inline-block; position: relative; width: 1.089em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.76em, 4.156em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-132" style="font-family: MathJax_Math; font-style: italic;">R</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.759em;"><span class="mi" id="MathJax-Span-133" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">t</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.268em; border-left: 0px solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>R</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-14">R_t</script>
 for all of the 20,000 actions in the batch of 100 Pong game rollouts 
above. One good idea is to “standardize” these returns (e.g. subtract 
mean, divide by standard deviation) before we plug them into backprop. 
This way we’re always encouraging and discouraging roughly half of the 
performed actions. Mathematically you can also interpret these tricks as
 a way of controlling the variance of the policy gradient estimator. A 
more in-depth exploration can be found <a href="http://arxiv.org/abs/1506.02438">here</a>.</p>

<p><strong>Deriving Policy Gradients</strong>. I’d like to also give a 
sketch of where Policy Gradients come from mathematically. Policy 
Gradients are a special case of a more general <em>score function gradient estimator</em>. The general case is that when we have an expression of the form <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;#x223C;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-134" style="width: 7.887em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.058em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1005.94em, 2.767em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-135"><span class="msubsup" id="MathJax-Span-136"><span style="display: inline-block; position: relative; width: 3.606em; height: 0px;"><span style="position: absolute; clip: rect(3.166em, 1000.76em, 4.135em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-137" style="font-family: MathJax_Math; font-style: italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.026em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.804em; left: 0.738em;"><span class="texatom" id="MathJax-Span-138"><span class="mrow" id="MathJax-Span-139"><span class="mi" id="MathJax-Span-140" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-141" style="font-size: 70.7%; font-family: MathJax_Main;">∼</span><span class="mi" id="MathJax-Span-142" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-143" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-144" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-145" style="font-size: 70.7%; font-family: MathJax_Main;">∣</span><span class="mi" id="MathJax-Span-146" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span><span class="mo" id="MathJax-Span-147" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-148" style="font-family: MathJax_Main;">[</span><span class="mi" id="MathJax-Span-149" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-150" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-151" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-152" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-153" style="font-family: MathJax_Main;">]</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.534em; border-left: 0px solid; width: 0px; height: 1.571em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mi>x</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo>∣</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-15">E_{x \sim p(x \mid \theta)} [f(x)] </script> - i.e. the expectation of some scalar valued score function <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-154" style="width: 2.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.875em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1001.78em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-155"><span class="mi" id="MathJax-Span-156" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-157" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-158" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-159" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-16">f(x)</script> under some probability distribution <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-160" style="width: 3.656em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.788em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1002.69em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-161"><span class="mi" id="MathJax-Span-162" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-163" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-164" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-165" style="font-family: MathJax_Main;">;</span><span class="mi" id="MathJax-Span-166" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">θ</span><span class="mo" id="MathJax-Span-167" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo>;</mo><mi>θ</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-17">p(x;\theta)</script> parameterized by some <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-168" style="width: 0.627em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.481em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.47em, 2.366em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-169"><span class="mi" id="MathJax-Span-170" style="font-family: MathJax_Math; font-style: italic;">θ</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.075em; border-left: 0px solid; width: 0px; height: 1.054em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><script type="math/tex" id="MathJax-Element-18">\theta</script>. Hint hint, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-171" style="width: 2.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.875em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1001.78em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-172"><span class="mi" id="MathJax-Span-173" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-174" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-175" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-176" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-19">f(x)</script> will become our reward function (or advantage function more generally) and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-177" style="width: 2.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.875em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1001.78em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-178"><span class="mi" id="MathJax-Span-179" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-180" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-181" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-182" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-20">p(x)</script> will be our policy network, which is really a model for <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-183" style="width: 4.089em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.125em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1003.03em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-184"><span class="mi" id="MathJax-Span-185" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-186" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-187" style="font-family: MathJax_Math; font-style: italic;">a</span><span class="mo" id="MathJax-Span-188" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="mi" id="MathJax-Span-189" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.278em;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.064em;"></span></span><span class="mo" id="MathJax-Span-190" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo>∣</mo><mi>I</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-21">p(a \mid I)</script>, giving a distribution over actions for any image <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-191" style="width: 0.627em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.481em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.384em, 1000.48em, 2.356em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-192"><span class="mi" id="MathJax-Span-193" style="font-family: MathJax_Math; font-style: italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.064em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.063em; border-left: 0px solid; width: 0px; height: 1.013em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>I</mi></math></span></span><script type="math/tex" id="MathJax-Element-22">I</script>. Then we are interested in finding how we should shift the distribution (through its parameters <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-194" style="width: 0.627em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.481em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.47em, 2.366em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-195"><span class="mi" id="MathJax-Span-196" style="font-family: MathJax_Math; font-style: italic;">θ</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.075em; border-left: 0px solid; width: 0px; height: 1.054em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><script type="math/tex" id="MathJax-Element-23">\theta</script>) to increase the scores of its samples, as judged by <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-197" style="width: 0.724em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.529em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.53em, 2.561em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-198"><span class="mi" id="MathJax-Span-199" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.329em; border-left: 0px solid; width: 0px; height: 1.308em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-24">f</script> (i.e. how do we change the network’s parameters so that action samples get higher rewards). We have that:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable columnalign=&quot;right left right left right left right left right left right left&quot; rowspacing=&quot;3pt&quot; columnspacing=&quot;0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em&quot; displaystyle=&quot;true&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mi&gt;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mtext&gt;definition of expectation&lt;/mtext&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd /&gt;&lt;mtd&gt;&lt;mi&gt;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mtext&gt;swap sum and gradient&lt;/mtext&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd /&gt;&lt;mtd&gt;&lt;mi&gt;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mtext&gt;both multiply and divide by&amp;#xA0;&lt;/mtext&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd /&gt;&lt;mtd&gt;&lt;mi&gt;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/munder&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mtext&gt;use the fact that&amp;#xA0;&lt;/mtext&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/mfrac&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd /&gt;&lt;mtd&gt;&lt;mi&gt;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mtext&gt;definition of expectation&lt;/mtext&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-200" style="width: 43.897em; display: inline-block;"><span style="display: inline-block; position: relative; width: 33.75em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(-3.975em, 1033.58em, 7.898em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-201"><span class="mtable" id="MathJax-Span-202" style="padding-right: 0.167em; padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 33.404em; height: 0px;"><span style="position: absolute; clip: rect(6.129em, 1004.79em, 17.552em, -1000em); top: -12.115em; left: 0em;"><span style="display: inline-block; position: relative; width: 4.913em; height: 0px;"><span style="position: absolute; clip: rect(3.096em, 1004.79em, 4.385em, -1000em); top: -9.082em; right: 0em;"><span class="mtd" id="MathJax-Span-203"><span class="mrow" id="MathJax-Span-204"><span class="msubsup" id="MathJax-Span-205"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-206" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-207"><span class="mrow" id="MathJax-Span-208"><span class="mi" id="MathJax-Span-209" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-210"><span style="display: inline-block; position: relative; width: 1.217em; height: 0px;"><span style="position: absolute; clip: rect(3.166em, 1000.76em, 4.135em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-211" style="font-family: MathJax_Math; font-style: italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.026em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.738em;"><span class="mi" id="MathJax-Span-212" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-213" style="font-family: MathJax_Main;">[</span><span class="mi" id="MathJax-Span-214" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-215" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-216" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-217" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-218" style="font-family: MathJax_Main;">]</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.846em, 1000em, 4.135em, -1000em); top: -6.675em; right: 0em;"><span class="mtd" id="MathJax-Span-242"><span class="mrow" id="MathJax-Span-243"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.846em, 1000em, 4.135em, -1000em); top: -3.757em; right: 0em;"><span class="mtd" id="MathJax-Span-267"><span class="mrow" id="MathJax-Span-268"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.846em, 1000em, 4.135em, -1000em); top: -0.956em; right: 0em;"><span class="mtd" id="MathJax-Span-307"><span class="mrow" id="MathJax-Span-308"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.846em, 1000em, 4.135em, -1000em); top: 1.302em; right: 0em;"><span class="mtd" id="MathJax-Span-358"><span class="mrow" id="MathJax-Span-359"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span><span style="display: inline-block; width: 0px; height: 12.115em;"></span></span><span style="position: absolute; clip: rect(6.41em, 1011.31em, 18.282em, -1000em); top: -12.596em; left: 4.913em;"><span style="display: inline-block; position: relative; width: 11.403em; height: 0px;"><span style="position: absolute; clip: rect(2.896em, 1008.01em, 5.292em, -1000em); top: -9.082em; left: 0em;"><span class="mtd" id="MathJax-Span-219"><span class="mrow" id="MathJax-Span-220"><span class="mi" id="MathJax-Span-221"></span><span class="mo" id="MathJax-Span-222" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="msubsup" id="MathJax-Span-223" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-224" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-225"><span class="mrow" id="MathJax-Span-226"><span class="mi" id="MathJax-Span-227" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="munderover" id="MathJax-Span-228" style="padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 1.444em; height: 0px;"><span style="position: absolute; clip: rect(2.896em, 1001.39em, 4.585em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-229" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.534em, 1000.37em, 4.242em, -1000em); top: -2.94em; left: 0.52em;"><span class="mi" id="MathJax-Span-230" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-231" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-232" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-233" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-234" style="font-family: MathJax_Main;">)</span><span class="mi" id="MathJax-Span-235" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-236" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-237" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-238" style="font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(2.896em, 1007.84em, 5.292em, -1000em); top: -6.675em; left: 0em;"><span class="mtd" id="MathJax-Span-244"><span class="mrow" id="MathJax-Span-245"><span class="mi" id="MathJax-Span-246"></span><span class="mo" id="MathJax-Span-247" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="munderover" id="MathJax-Span-248" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 1.444em; height: 0px;"><span style="position: absolute; clip: rect(2.896em, 1001.39em, 4.585em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-249" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.534em, 1000.37em, 4.242em, -1000em); top: -2.94em; left: 0.52em;"><span class="mi" id="MathJax-Span-250" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-251" style="padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-252" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-253"><span class="mrow" id="MathJax-Span-254"><span class="mi" id="MathJax-Span-255" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-256" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-257" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-258" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-259" style="font-family: MathJax_Main;">)</span><span class="mi" id="MathJax-Span-260" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-261" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-262" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-263" style="font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(2.386em, 1010.06em, 5.292em, -1000em); top: -3.757em; left: 0em;"><span class="mtd" id="MathJax-Span-269"><span class="mrow" id="MathJax-Span-270"><span class="mi" id="MathJax-Span-271"></span><span class="mo" id="MathJax-Span-272" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="munderover" id="MathJax-Span-273" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 1.444em; height: 0px;"><span style="position: absolute; clip: rect(2.896em, 1001.39em, 4.585em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-274" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.534em, 1000.37em, 4.242em, -1000em); top: -2.94em; left: 0.52em;"><span class="mi" id="MathJax-Span-275" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-276" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-277" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-278" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-279" style="font-family: MathJax_Main;">)</span><span class="mfrac" id="MathJax-Span-280"><span style="display: inline-block; position: relative; width: 3.213em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.096em, 1003em, 4.385em, -1000em); top: -4.701em; left: 50%; margin-left: -1.546em;"><span class="mrow" id="MathJax-Span-281"><span class="msubsup" id="MathJax-Span-282"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-283" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-284"><span class="mrow" id="MathJax-Span-285"><span class="mi" id="MathJax-Span-286" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-287" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-288" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-289" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-290" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.096em, 1001.76em, 4.385em, -1000em); top: -3.28em; left: 50%; margin-left: -0.926em;"><span class="mrow" id="MathJax-Span-291"><span class="mi" id="MathJax-Span-292" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-293" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-294" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-295" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(0.853em, 1003.21em, 1.202em, -1000em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.213em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.058em;"></span></span></span></span><span class="mi" id="MathJax-Span-296" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-297" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-298" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-299" style="font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(2.896em, 1011.31em, 5.292em, -1000em); top: -0.956em; left: 0em;"><span class="mtd" id="MathJax-Span-309"><span class="mrow" id="MathJax-Span-310"><span class="mi" id="MathJax-Span-311"></span><span class="mo" id="MathJax-Span-312" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="munderover" id="MathJax-Span-313" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 1.444em; height: 0px;"><span style="position: absolute; clip: rect(2.896em, 1001.39em, 4.585em, -1000em); top: -3.99em; left: 0em;"><span class="mo" id="MathJax-Span-314" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.534em, 1000.37em, 4.242em, -1000em); top: -2.94em; left: 0.52em;"><span class="mi" id="MathJax-Span-315" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-316" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-317" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-318" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-319" style="font-family: MathJax_Main;">)</span><span class="msubsup" id="MathJax-Span-320"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-321" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-322"><span class="mrow" id="MathJax-Span-323"><span class="mi" id="MathJax-Span-324" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-325" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-326"></span><span class="mi" id="MathJax-Span-327" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-328" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-329" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-330" style="font-family: MathJax_Main;">)</span><span class="mi" id="MathJax-Span-331" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-332" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-333" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-334" style="font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.096em, 1009.59em, 4.385em, -1000em); top: 1.302em; left: 0em;"><span class="mtd" id="MathJax-Span-360"><span class="mrow" id="MathJax-Span-361"><span class="mi" id="MathJax-Span-362"></span><span class="mo" id="MathJax-Span-363" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="msubsup" id="MathJax-Span-364" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 1.217em; height: 0px;"><span style="position: absolute; clip: rect(3.166em, 1000.76em, 4.135em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-365" style="font-family: MathJax_Math; font-style: italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.026em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.738em;"><span class="mi" id="MathJax-Span-366" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">x</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mo" id="MathJax-Span-367" style="font-family: MathJax_Main;">[</span><span class="mi" id="MathJax-Span-368" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-369" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-370" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-371" style="font-family: MathJax_Main;">)</span><span class="msubsup" id="MathJax-Span-372"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-373" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-374"><span class="mrow" id="MathJax-Span-375"><span class="mi" id="MathJax-Span-376" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-377" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-378"></span><span class="mi" id="MathJax-Span-379" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-380" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-381" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-382" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-383" style="font-family: MathJax_Main;">]</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span><span style="display: inline-block; width: 0px; height: 12.596em;"></span></span><span style="position: absolute; clip: rect(6.318em, 1015.09em, 17.89em, -1000em); top: -12.26em; left: 18.316em;"><span style="display: inline-block; position: relative; width: 15.088em; height: 0px;"><span style="position: absolute; clip: rect(3.141em, 1010.46em, 4.329em, -1000em); top: -9.082em; right: 0em;"><span class="mtd" id="MathJax-Span-239"><span class="mrow" id="MathJax-Span-240"><span class="mtext" id="MathJax-Span-241" style="font-family: MathJax_Main;">definition of expectation</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.152em, 1009.88em, 4.341em, -1000em); top: -6.675em; right: 0em;"><span class="mtd" id="MathJax-Span-264"><span class="mrow" id="MathJax-Span-265"><span class="mtext" id="MathJax-Span-266" style="font-family: MathJax_Main;">swap sum and gradient</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.096em, 1014.04em, 4.385em, -1000em); top: -3.757em; right: 0em;"><span class="mtd" id="MathJax-Span-300"><span class="mrow" id="MathJax-Span-301"><span class="mtext" id="MathJax-Span-302" style="font-family: MathJax_Main;">both multiply and divide by&nbsp;</span><span class="mi" id="MathJax-Span-303" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-304" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-305" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-306" style="font-family: MathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(2.504em, 1015.09em, 4.832em, -1000em); top: -0.956em; right: 0em;"><span class="mtd" id="MathJax-Span-335"><span class="mrow" id="MathJax-Span-336"><span class="mtext" id="MathJax-Span-337" style="font-family: MathJax_Main;">use the fact that&nbsp;</span><span class="msubsup" id="MathJax-Span-338"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-339" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-340"><span class="mrow" id="MathJax-Span-341"><span class="mi" id="MathJax-Span-342" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-343" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-344"></span><span class="mo" id="MathJax-Span-345" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-346" style="font-family: MathJax_Math; font-style: italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-347" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-348" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mfrac" id="MathJax-Span-349" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 0.62em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.18em, 1000.43em, 4.135em, -1000em); top: -4.667em; left: 50%; margin-left: -0.25em;"><span class="mn" id="MathJax-Span-350" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.404em, 1000.47em, 4.146em, -1000em); top: -3.304em; left: 50%; margin-left: -0.234em;"><span class="mi" id="MathJax-Span-351" style="font-family: MathJax_Math; font-style: italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(0.853em, 1000.62em, 1.202em, -1000em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.62em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.058em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-352"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-353" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-354"><span class="mrow" id="MathJax-Span-355"><span class="mi" id="MathJax-Span-356" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-357" style="font-family: MathJax_Math; font-style: italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; clip: rect(3.141em, 1010.46em, 4.329em, -1000em); top: 1.302em; right: 0em;"><span class="mtd" id="MathJax-Span-384"><span class="mrow" id="MathJax-Span-385"><span class="mtext" id="MathJax-Span-386" style="font-family: MathJax_Main;">definition of expectation</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span><span style="display: inline-block; width: 0px; height: 12.26em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -7.267em; border-left: 0px solid; width: 0px; height: 15.184em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mtr><mtd><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><msub><mi>E</mi><mi>x</mi></msub><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mtd><mtd><mi></mi><mo>=</mo><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><munder><mo>∑</mo><mi>x</mi></munder><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mtd><mtd><mtext>definition of expectation</mtext></mtd></mtr><mtr><mtd></mtd><mtd><mi></mi><mo>=</mo><munder><mo>∑</mo><mi>x</mi></munder><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mtd><mtd><mtext>swap sum and gradient</mtext></mtd></mtr><mtr><mtd></mtd><mtd><mi></mi><mo>=</mo><munder><mo>∑</mo><mi>x</mi></munder><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mfrac><mrow><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mtd><mtd><mtext>both multiply and divide by&nbsp;</mtext><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd></mtd><mtd><mi></mi><mo>=</mo><munder><mo>∑</mo><mi>x</mi></munder><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mtd><mtd><mtext>use the fact that&nbsp;</mtext><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>z</mi></mfrac><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>z</mi></mtd></mtr><mtr><mtd></mtd><mtd><mi></mi><mo>=</mo><msub><mi>E</mi><mi>x</mi></msub><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mtd><mtd><mtext>definition of expectation</mtext></mtd></mtr></mtable></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-25">% <![CDATA[
\begin{align}
\nabla_{\theta} E_x[f(x)] &= \nabla_{\theta} \sum_x p(x) f(x) & \text{definition of expectation} \\
& = \sum_x \nabla_{\theta} p(x) f(x) & \text{swap sum and gradient} \\
& = \sum_x p(x) \frac{\nabla_{\theta} p(x)}{p(x)} f(x) & \text{both multiply and divide by } p(x) \\
& = \sum_x p(x) \nabla_{\theta} \log p(x) f(x) & \text{use the fact that } \nabla_{\theta} \log(z) = \frac{1}{z} \nabla_{\theta} z \\
& = E_x[f(x) \nabla_{\theta} \log p(x) ] & \text{definition of expectation}
\end{align} %]]></script>

<p>To put this in English, we have some distribution <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-387" style="width: 3.656em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.788em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1002.69em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-388"><span class="mi" id="MathJax-Span-389" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-390" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-391" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-392" style="font-family: MathJax_Main;">;</span><span class="mi" id="MathJax-Span-393" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">θ</span><span class="mo" id="MathJax-Span-394" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo>;</mo><mi>θ</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-26">p(x;\theta)</script> (I used shorthand <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-395" style="width: 2.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.875em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1001.78em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-396"><span class="mi" id="MathJax-Span-397" style="font-family: MathJax_Math; font-style: italic;">p</span><span class="mo" id="MathJax-Span-398" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-399" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-400" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-27">p(x)</script>
 to reduce clutter) that we can sample from (e.g. this could be a 
gaussian). For each sample we can also evaluate the score function <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-28-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-401" style="width: 0.724em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.529em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.53em, 2.561em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-402"><span class="mi" id="MathJax-Span-403" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.329em; border-left: 0px solid; width: 0px; height: 1.308em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-28">f</script>
 which takes the sample and gives us some scalar-valued score. This 
equation is telling us how we should shift the distribution (through its
 parameters <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-404" style="width: 0.627em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.481em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.47em, 2.366em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-405"><span class="mi" id="MathJax-Span-406" style="font-family: MathJax_Math; font-style: italic;">θ</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.075em; border-left: 0px solid; width: 0px; height: 1.054em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><script type="math/tex" id="MathJax-Element-29">\theta</script>) if we wanted its samples to achieve higher scores, as judged by <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-407" style="width: 0.724em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.529em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.53em, 2.561em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-408"><span class="mi" id="MathJax-Span-409" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.329em; border-left: 0px solid; width: 0px; height: 1.308em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-30">f</script>. In particular, it says that look: draw some samples <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-410" style="width: 0.772em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.577em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.53em, 2.367em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-411"><span class="mi" id="MathJax-Span-412" style="font-family: MathJax_Math; font-style: italic;">x</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.077em; border-left: 0px solid; width: 0px; height: 0.714em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-31">x</script>, evaluate their scores <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-413" style="width: 2.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.875em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1001.78em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-414"><span class="mi" id="MathJax-Span-415" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-416" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-417" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-418" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-32">f(x)</script>, and for each <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-33-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-419" style="width: 0.772em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.577em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.53em, 2.367em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-420"><span class="mi" id="MathJax-Span-421" style="font-family: MathJax_Math; font-style: italic;">x</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.077em; border-left: 0px solid; width: 0px; height: 0.714em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-33">x</script> also evaluate the second term <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-422" style="width: 7.406em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.673em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1005.58em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-423"><span class="msubsup" id="MathJax-Span-424"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-425" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-426"><span class="mrow" id="MathJax-Span-427"><span class="mi" id="MathJax-Span-428" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-429" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-430"></span><span class="mi" id="MathJax-Span-431" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-432" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-433" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-434" style="font-family: MathJax_Main;">;</span><span class="mi" id="MathJax-Span-435" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">θ</span><span class="mo" id="MathJax-Span-436" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo>;</mo><mi>θ</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-34"> \nabla_{\theta} \log p(x;\theta) </script>.
 What is this second term? It’s a vector - the gradient that’s giving us
 the direction in the parameter space that would lead to increase of the
 probability assigned to an <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-35-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-437" style="width: 0.772em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.577em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.53em, 2.367em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-438"><span class="mi" id="MathJax-Span-439" style="font-family: MathJax_Math; font-style: italic;">x</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.077em; border-left: 0px solid; width: 0px; height: 0.714em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-35">x</script>. In other words if we were to nudge <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-36-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-440" style="width: 0.627em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.481em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.362em, 1000.47em, 2.366em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-441"><span class="mi" id="MathJax-Span-442" style="font-family: MathJax_Math; font-style: italic;">θ</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.075em; border-left: 0px solid; width: 0px; height: 1.054em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>θ</mi></math></span></span><script type="math/tex" id="MathJax-Element-36">\theta</script> in the direction of <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-37-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2207;&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-443" style="width: 7.406em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.673em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1005.58em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-444"><span class="msubsup" id="MathJax-Span-445"><span style="display: inline-block; position: relative; width: 1.24em; height: 0px;"><span style="position: absolute; clip: rect(3.163em, 1000.79em, 4.168em, -1000em); top: -3.99em; left: 0em;"><span class="mi" id="MathJax-Span-446" style="font-family: MathJax_Main;">∇</span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span><span style="position: absolute; top: -3.836em; left: 0.833em;"><span class="texatom" id="MathJax-Span-447"><span class="mrow" id="MathJax-Span-448"><span class="mi" id="MathJax-Span-449" style="font-size: 70.7%; font-family: MathJax_Math; font-style: italic;">θ</span></span></span><span style="display: inline-block; width: 0px; height: 3.99em;"></span></span></span></span><span class="mi" id="MathJax-Span-450" style="font-family: MathJax_Main; padding-left: 0.167em;">log</span><span class="mo" id="MathJax-Span-451"></span><span class="mi" id="MathJax-Span-452" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">p</span><span class="mo" id="MathJax-Span-453" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-454" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-455" style="font-family: MathJax_Main;">;</span><span class="mi" id="MathJax-Span-456" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.167em;">θ</span><span class="mo" id="MathJax-Span-457" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="normal">∇</mi><mrow class="MJX-TeXAtom-ORD"><mi>θ</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo>;</mo><mi>θ</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-37"> \nabla_{\theta} \log p(x;\theta) </script> we would see the new probability assigned to some <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-38-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-458" style="width: 0.772em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.577em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.53em, 2.367em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-459"><span class="mi" id="MathJax-Span-460" style="font-family: MathJax_Math; font-style: italic;">x</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.077em; border-left: 0px solid; width: 0px; height: 0.714em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-38">x</script>
 slightly increase. If you look back at the formula, it’s telling us 
that we should take this direction and multiply onto it the 
scalar-valued score <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-39-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-461" style="width: 2.454em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.875em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.365em, 1001.78em, 2.654em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-462"><span class="mi" id="MathJax-Span-463" style="font-family: MathJax_Math; font-style: italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.06em;"></span></span><span class="mo" id="MathJax-Span-464" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-465" style="font-family: MathJax_Math; font-style: italic;">x</span><span class="mo" id="MathJax-Span-466" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.388em; border-left: 0px solid; width: 0px; height: 1.425em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-39">f(x)</script>.
 This will make it so that samples that have a higher score will “tug” 
on the probability density stronger than the samples that have lower 
score, so if we were to do an update based on several samples from <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-40-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-467" style="width: 0.724em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.529em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.625em, 1000.52em, 2.55em, -1000em); top: -2.212em; left: 0em;"><span class="mrow" id="MathJax-Span-468"><span class="mi" id="MathJax-Span-469" style="font-family: MathJax_Math; font-style: italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.212em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.315em; border-left: 0px solid; width: 0px; height: 0.952em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-40">p</script> the probability density would shift around in the direction of higher scores, making highly-scoring samples more likely.</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/pg.png">
<div class="thecap" style="text-align:justify;">
	A visualization of the score function gradient estimator. <b>Left</b>: A
 gaussian distribution and a few samples from it (blue dots). On each 
blue dot we also plot the gradient of the log probability with respect 
to the gaussian's mean parameter. The arrow indicates the direction in 
which the mean of the distribution should be nudged to increase the 
probability of that sample. <b>Middle</b>: Overlay of some score 
function giving -1 everywhere except +1 in some small regions (note this
 can be an arbitrary and not necessarily differentiable scalar-valued 
function). The arrows are now color coded because due to the 
multiplication in the update we are going to average up all the green 
arrows, and the <i>negative</i> of the red arrows. <b>Right</b>: after 
parameter update, the green arrows and the reversed red arrows nudge us 
to left and towards the bottom. Samples from this distribution will now 
have a higher expected score, as desired.
</div>
</div>

<p>I hope the connection to RL is clear. Our policy network gives us 
samples of actions, and some of them work better than others (as judged 
by the advantage function). This little piece of math is telling us that
 the way to change the policy’s parameters is to do some rollouts, take 
the gradient of the sampled actions, multiply it by the score and add 
everything, which is what we’ve done above. For a more thorough 
derivation and discussion I recommend <a href="https://www.youtube.com/watch?v=oPGVsoBonLM">John Schulman’s lecture</a>.</p>

<p><strong>Learning</strong>. Alright, we’ve developed the intuition for
 policy gradients and saw a sketch of their derivation. I implemented 
the whole approach in a <a href="https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5">130-line Python script</a>, which uses <a href="https://gym.openai.com/">OpenAI Gym</a>’s
 ATARI 2600 Pong. I trained a 2-layer policy network with 200 hidden 
layer units using RMSProp on batches of 10 episodes (each episode is a 
few dozen games, because the games go up to score of 21 for either 
player). I did not tune the hyperparameters too much and ran the 
experiment on my (slow) Macbook, but after training for 3 nights I ended
 up with a policy that is slightly better than the AI player. The total 
number of episodes was approximately 8,000 so the algorithm played 
roughly 200,000 Pong games (quite a lot isn’t it!) and made a total of 
~800 updates. I’m told by friends that if you train on GPU with ConvNets
 for a few days you can beat the AI player more often, and if you also 
optimize hyperparameters carefully you can also consistently dominate 
the AI player (i.e. win every single game). However, I didn’t spend too 
much time computing or tweaking, so instead we end up with a Pong AI 
that illustrates the main ideas and works quite well:</p>

<div style="text-align:center;">
<iframe src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/YOW8m2YGtRg.htm" allowfullscreen="" frameborder="0" width="420" height="315"></iframe>
<br>
The learned agent (in green, right) facing off with the hard-coded AI opponent (left).
</div>

<p><strong>Learned weights</strong>. We can also take a look at the 
learned weights. Due to preprocessing every one of our inputs is an 
80x80 difference image (current frame minus last frame). We can now take
 every row of <code class="highlighter-rouge">W1</code>, stretch them 
out to 80x80 and visualize. Below is a collection of 40 (out of 200) 
neurons in a grid. White pixels are positive weights and black pixels 
are negative weights. Notice that several neurons are tuned to 
particular traces of bouncing ball, encoded with alternating black and 
white along the line. The ball can only be at a single spot, so these 
neurons are multitasking and will “fire” for multiple locations of the 
ball along that line. The alternating black and white is interesting 
because as the ball travels along the trace, the neuron’s activity will 
fluctuate as a sine wave and due to the ReLU it would “fire” at 
discrete, separated positions along the trace. There’s a bit of noise in
 the images, which I assume would have been mitigated if I used L2 
regularization.</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/weights.png">
</div>

<h3 id="what-isnt-happening">What isn’t happening</h3>

<p>So there you have it - we learned to play Pong from from raw pixels 
with Policy Gradients and it works quite well. The approach is a fancy 
form of guess-and-check, where the “guess” refers to sampling rollouts 
from our current policy, and the “check” refers to encouraging actions 
that lead to good outcomes. Modulo some details, this represents the 
state of the art in how we currently approach reinforcement learning 
problems. Its impressive that we can learn these behaviors, but if you 
understood the algorithm intuitively and you know how it works you 
should be at least a bit disappointed. In particular, how does it not 
work?</p>

<p>Compare that to how a human might learn to play Pong. You show them 
the game and say something along the lines of “You’re in control of a 
paddle and you can move it up and down, and your task is to bounce the 
ball past the other player controlled by AI”, and you’re set and ready 
to go. Notice some of the differences:</p>

<ul>
  <li>In practical settings we usually communicate the task in some 
manner (e.g. English above), but in a standard RL problem you assume an 
arbitrary reward function that you have to discover through environment 
interactions. It can be argued that if a human went into game of Pong 
but without knowing anything about the reward function (indeed, 
especially if the reward function was some static but random function), 
the human would have a lot of difficulty learning what to do but Policy 
Gradients would be indifferent, and likely work much better. Similarly, 
if we took the frames and permuted the pixels randomly then humans would
 likely fail, but our Policy Gradient solution could not even tell the 
difference (if it’s using a fully connected network as done here).</li>
  <li>A human brings in a huge amount of prior knowledge, such as 
intuitive physics (the ball bounces, it’s unlikely to teleport, it’s 
unlikely to suddenly stop, it maintains a constant velocity, etc.), and 
intuitive psychology (the AI opponent “wants” to win, is likely 
following an obvious strategy of moving towards the ball, etc.). You 
also understand the concept of being “in control” of a paddle, and that 
it responds to your UP/DOWN key commands. In contrast, our algorithms 
start from scratch which is simultaneously impressive (because it works)
 and depressing (because we lack concrete ideas for how not to).</li>
  <li>Policy Gradients are a <em>brute force</em> solution, where the 
correct actions are eventually discovered and internalized into a 
policy. Humans build a rich, abstract model and plan within it. In Pong,
 I can reason that the opponent is quite slow so it might be a good 
strategy to bounce the ball with high vertical velocity, which would 
cause the opponent to not catch it in time. However, it also feels as 
though we also eventually “internalize” good solutions into what feels 
more like a reactive muscle memory policy. For example if you’re 
learning a new motor task (e.g. driving a car with stick shift?) you 
often feel yourself thinking a lot in the beginning but eventually the 
task becomes automatic and mindless.</li>
  <li>Policy Gradients have to actually experience a positive reward, 
and experience it very often in order to eventually and slowly shift the
 policy parameters towards repeating moves that give high rewards. With 
our abstract model, humans can figure out what is likely to give rewards
 without ever actually experiencing the rewarding or unrewarding 
transition. I don’t have to actually experience crashing my car into a 
wall a few hundred times before I slowly start avoiding to do so.</li>
</ul>

<div class="imgcap">
<div style="display:inline-block">
	<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/montezuma.png" height="250">
</div>
<div style="display:inline-block; margin-left: 20px;">
	<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/frostbite.jpg" height="250">
</div>
<div class="thecap" style="text-align:justify;"><b>Left:</b> Montezuma's
 Revenge: a difficult game for our RL algorithms. The player must jump 
down, climb up, get the key, and open the door. A human understands that
 acquiring a key is useful. The computer samples billions of random 
moves and 99% of the time falls to its death or gets killed by the 
monster. In other words it's hard to "stumble into" the rewarding 
situation. <b>Right:</b> Another difficult game called Frostbite, where a
 human understands that things move, some things are good to touch, some
 things are bad to touch, and the goal is to build the igloo brick by 
brick. A good analysis of this game and a discussion of differences 
between the human and computer approach can be found in <a href="https://arxiv.org/abs/1604.00289">Building Machines That Learn and Think Like People</a>.</div>
</div>

<p>I’d like to also emphasize the point that, conversely, there are many
 games where Policy Gradients would quite easily defeat a human. In 
particular, anything with frequent reward signals that requires precise 
play, fast reflexes, and not too much long-term planning would be ideal,
 as these short-term correlations between rewards and actions can be 
easily “noticed” by the approach, and the execution meticulously 
perfected by the policy. You can see hints of this already happening in 
our Pong agent: it develops a strategy where it waits for the ball and 
then rapidly dashes to catch it just at the edge, which launches it 
quickly and with high vertical velocity. The agent scores several points
 in a row repeating this strategy. There are many ATARI games where Deep
 Q Learning destroys human baseline performance in this fashion - e.g. 
Pinball, Breakout, etc.</p>

<p>In conclusion, once you understand the “trick” by which these 
algorithms work you can reason through their strengths and weaknesses. 
In particular, we are nowhere near humans in building abstract, rich 
representations of games that we can plan within and use for rapid 
learning. One day a computer will look at an array of pixels and notice a
 key, a door, and think to itself that it is probably a good idea to 
pick up the key and reach the door. For now there is nothing anywhere 
close to this, and trying to get there is an active area of research.</p>

<h3 id="non-differentiable-computation-in-neural-networks">Non-differentiable computation in Neural Networks</h3>

<p>I’d like to mention one more interesting application of Policy 
Gradients unrelated to games: It allows us to design and train neural 
networks with components that perform (or interact with) 
non-differentiable computation. The idea was first introduced in <a href="http://www-anw.cs.umass.edu/%7Ebarto/courses/cs687/williams92simple.pdf">Williams 1992</a> and more recently popularized by <a href="http://arxiv.org/abs/1406.6247">Recurrent Models of Visual Attention</a>
 under the name “hard attention”, in the context of a model that 
processed an image with a sequence of low-resolution foveal glances 
(inspired by our own human eyes). In particular, at every iteration an 
RNN would receive a small piece of the image and sample a location to 
look at next. For example the RNN might look at position (5,30), receive
 a small piece of the image, then decide to look at (24, 50), etc. The 
problem with this idea is that there a piece of network that produces a 
distribution of where to look next and then samples from it. 
Unfortunately, this operation is non-differentiable because, 
intuitively, we don’t know what would have happened if we sampled a 
different location. More generally, consider a neural network from some 
inputs to outputs:</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/nondiff1.png" width="600">
</div>

<p>Notice that most arrows (in blue) are differentiable as normal, but 
some of the representation transformations could optionally also include
 a non-differentiable sampling operation (in red). We can backprop 
through the blue arrows just fine, but the red arrow represents a 
dependency that we cannot backprop through.</p>

<p>Policy gradients to the rescue! We’ll think about the part of the 
network that does the sampling as a small stochastic policy embedded in 
the wider network. Therefore, during training we will produce several 
samples (indicated by the branches below), and then we’ll encourage 
samples that eventually led to good outcomes (in this case for example 
measured by the loss at the end). In other words we will train the 
parameters involved in the blue arrows with backprop as usual, but the 
parameters involved with the red arrow will now be updated independently
 of the backward pass using policy gradients, encouraging samples that 
led to low loss. This idea was also recently formalized nicely in <a href="http://arxiv.org/abs/1506.05254">Gradient Estimation Using Stochastic Computation Graphs</a>.</p>

<div class="imgcap">
<img src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/nondiff2.png" width="600">
</div>

<p><strong>Trainable Memory I/O</strong>. You’ll also find this idea in many other papers. For example, a <a href="https://arxiv.org/abs/1410.5401">Neural Turing Machine</a> has a memory tape that they it read and write from. To do a write operation one would like to execute something like <code class="highlighter-rouge">m[i] = x</code>, where <code class="highlighter-rouge">i</code> and <code class="highlighter-rouge">x</code>
 are predicted by an RNN controller network. However, this operation is 
non-differentiable because there is no signal telling us what would have
 happened to the loss if we were to write to a different location <code class="highlighter-rouge">j != i</code>. Therefore, the NTM has to do <em>soft</em> read and write operations. It predicts an attention distribution <code class="highlighter-rouge">a</code> (with elements between 0 and 1 and summing to 1, and peaky around the index we’d like to write to), and then doing <code class="highlighter-rouge">for all i: m[i] = a[i]*x</code>.
 This is now differentiable, but we have to pay a heavy computational 
price because we have to touch every single memory cell just to write to
 one position. Imagine if every assignment in our computers had to touch
 the entire RAM!</p>

<p>However, we can use policy gradients to circumvent this problem (in theory), as done in <a href="http://arxiv.org/abs/1505.00521">RL-NTM</a>. We still predict an attention distribution <code class="highlighter-rouge">a</code>, but instead of doing the soft write we sample locations to write to: <code class="highlighter-rouge">i = sample(a); m[i] = x</code>. During training we would do this for a small batch of <code class="highlighter-rouge">i</code>,
 and in the end make whatever branch worked best more likely. The large 
computational advantage is that we now only have to read/write at a 
single location at test time. However, as pointed out in the paper this 
strategy is very difficult to get working because one must accidentally 
stumble by working algorithms through sampling. The current consensus is
 that PG works well only in settings where there are a few discrete 
choices so that one is not hopelessly sampling through huge search 
spaces.</p>

<p>However, with Policy Gradients and in cases where a lot of 
data/compute is available we can in principle dream big - for instance 
we can design neural networks that learn to interact with large, 
non-differentiable modules such as Latex compilers (e.g. if you’d like 
char-rnn to generate latex that compiles), or a SLAM system, or LQR 
solvers, or something. Or, for example, a superintelligence might want 
to learn to interact with the internet over TCP/IP (which is sadly 
non-differentiable) to access vital information needed to take over the 
world. That’s a great example.</p>

<h3 id="conclusions">Conclusions</h3>

<p>We saw that Policy Gradients are a powerful, general algorithm and as
 an example we trained an ATARI Pong agent from raw pixels, from 
scratch, in <a href="https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5">130 lines of Python</a>.
 More generally the same algorithm can be used to train agents for 
arbitrary games and one day hopefully on many valuable real-world 
control problems. I wanted to add a few more notes in closing:</p>

<p><strong>On advancing AI</strong>. We saw that the algorithm works 
through a brute-force search where you jitter around randomly at first 
and must accidentally stumble into rewarding situations at least once, 
and ideally often and repeatedly before the policy distribution shifts 
its parameters to repeat the responsible actions. We also saw that 
humans approach these problems very differently, in what feels more like
 rapid abstract model building - something we have barely even scratched
 the surface of in research (although many people are trying). Since 
these abstract models are very difficult (if not impossible) to 
explicitly annotate, this is also why there is so much interest recently
 in (unsupervised) generative models and program induction.</p>

<p><strong>On use in complex robotics settings</strong>. The algorithm 
does not scale naively to settings where huge amounts of exploration are
 difficult to obtain. For instance, in robotic settings one might have a
 single (or few) robots, interacting with the world in real time. This 
prohibits naive applications of the algorithm as I presented it in this 
post. One related line of work intended to mitigate this problem is <a href="http://jmlr.org/proceedings/papers/v32/silver14.pdf">deterministic policy gradients</a>
 - instead of requiring samples from a stochastic policy and encouraging
 the ones that get higher scores, the approach uses a deterministic 
policy and gets the gradient information directly from a second network 
(called a <em>critic</em>) that models the score function. This approach
 can in principle be much more efficient in settings with very 
high-dimensional actions where sampling actions provides poor coverage, 
but so far seems empirically slightly finicky to get working. Another 
related approach is to scale up robotics, as we’re starting to see with <a href="http://googleresearch.blogspot.com/2016/03/deep-learning-for-robots-learning-from.html">Google’s robot arm farm</a>, or perhaps even <a href="http://qz.com/694520/tesla-has-780-million-miles-of-driving-data-and-adds-another-million-every-10-hours/">Tesla’s Model S + Autopilot</a>.</p>

<p>There is also a line of work that tries to make the search process 
less hopeless by adding additional supervision. In many practical cases,
 for instance, one can obtain expert trajectories from a human. For 
example <a href="https://deepmind.com/alpha-go">AlphaGo</a> first uses 
supervised learning to predict human moves from expert Go games and the 
resulting human mimicking policy is later finetuned with policy 
gradients on the “real” objective of winning the game. In some cases one
 might have fewer expert trajectories (e.g. from <a href="https://www.youtube.com/watch?v=kZlg0QvKkQQ">robot teleoperation</a>) and there are techniques for taking advantage of this data under the umbrella of <a href="http://ai.stanford.edu/%7Epabbeel//thesis/thesis.pdf">apprenticeship learning</a>.
 Finally, if no supervised data is provided by humans it can also be in 
some cases computed with expensive optimization techniques, e.g. by <a href="http://people.eecs.berkeley.edu/%7Eigor.mordatch/policy/index.html">trajectory optimization</a> in a known dynamics model (such as <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-41-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-470" style="width: 4.57em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.51em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.435em, 1003.49em, 2.415em, -1000em); top: -2.26em; left: 0em;"><span class="mrow" id="MathJax-Span-471"><span class="mi" id="MathJax-Span-472" style="font-family: MathJax_Math; font-style: italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.106em;"></span></span><span class="mo" id="MathJax-Span-473" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mi" id="MathJax-Span-474" style="font-family: MathJax_Math; font-style: italic; padding-left: 0.278em;">m</span><span class="mi" id="MathJax-Span-475" style="font-family: MathJax_Math; font-style: italic;">a</span></span><span style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.077em; border-left: 0px solid; width: 0px; height: 1.023em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mo>=</mo><mi>m</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-41">F=ma</script>
 in a physical simulator), or in cases where one learns an approximate 
local dynamics model (as seen in very promising framework of <a href="http://arxiv.org/abs/1504.00702">Guided Policy Search</a>).</p>

<p><strong>On using PG in practice</strong>. As a last note, I’d like to
 do something I wish I had done in my RNN blog post. I think I may have 
given the impression that RNNs are magic and automatically do arbitrary 
sequential problems. The truth is that getting these models to work can 
be tricky, requires care and expertise, and in many cases could also be 
an overkill, where simpler methods could get you 90%+ of the way there. 
The same goes for Policy Gradients. They are not automatic: You need a 
lot of samples, it trains forever, it is difficult to debug when it 
doesn’t work. One should always try a BB gun before reaching for the 
Bazooka. In the case of Reinforcement Learning for example, one strong 
baseline that should always be tried first is the <a href="https://en.wikipedia.org/wiki/Cross-entropy_method">cross-entropy method (CEM)</a>,
 a simple stochastic hill-climbing “guess and check” approach inspired 
loosely by evolution. And if you insist on trying out Policy Gradients 
for your problem make sure you pay close attention to the <em>tricks</em> section in papers, start simple first, and use a variation of PG called <a href="https://arxiv.org/abs/1502.05477">TRPO</a>, which almost always works better and more consistently than vanilla PG <a href="http://arxiv.org/abs/1604.06778">in practice</a>.
 The core idea is to avoid parameter updates that change your policy too
 much, as enforced by a constraint on the KL divergence between the 
distributions predicted by the old and the new policy on a batch of data
 (instead of conjugate gradients the simplest instantiation of this idea
 could be implemented by doing a line search and checking the KL along 
the way).</p>

<p>And that’s it! I hope I gave you a sense of where we are with 
Reinforcement Learning, what the challenges are, and if you’re eager to 
help advance RL I invite you to do so within our <a href="https://gym.openai.com/">OpenAI Gym</a> :) Until next time!</p>

  </article>

  <!-- mathjax -->
  
  <script type="text/javascript" src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/MathJax.js"></script>
  
  
  <!-- disqus comments -->
 
 <div id="disqus_thread"><iframe id="dsq-app1" name="dsq-app1" allowtransparency="true" scrolling="no" tabindex="0" title="Disqus" style="width: 1px ! important; min-width: 100% ! important; border: medium none ! important; overflow: hidden ! important; height: 10501px ! important;" src="Deep%20Reinforcement%20Learning:%20Pong%20from%20Pixels_files/a.htm" horizontalscrolling="no" verticalscrolling="no" frameborder="0" width="100%"></iframe></div>
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'karpathyblog'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  
  
  
</div>
      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <!-- <h2 class="footer-heading">Andrej Karpathy blog</h2> -->

    <div class="footer-col-1 column">
      <ul>
        <li>Andrej Karpathy blog</li>
        <!-- <li><a href="mailto:"></a></li> -->
      </ul>
    </div>

    <div class="footer-col-2 column">
      <ul>
        <li>
          <a href="https://github.com/karpathy">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"></path>
              </svg>
            </span>
            <span class="username">karpathy</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/karpathy">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
              </svg>
            </span>
            <span class="username">karpathy</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">
      <p class="text">Musings of a Computer Scientist.</p>
    </div>

  </div>

</footer>


    
<iframe style="display: none;"></iframe><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px none; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px none; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-size-adjust: none; font-family: MathJax_Size2,sans-serif;"></div></div></body></html>